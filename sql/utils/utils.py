import json
import os
import pathlib
import sqlite3
import re
from openai import OpenAI
from pathlib import Path
from typing import List, Dict, Any, Optional, Union, Callable

# --- Configuration --- #
client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY"),
    timeout=30.0  # 30 second timeout for API calls
)


def llm_chat(
    model: str,
    messages: List[Dict[str, str]],
    temperature: float,
    seed: Optional[int],
) -> str:
    """
    Basic LLM chat function with timeout and retry logic.
    Args:
        model: The model name to use
        messages: List of message dictionaries with 'role' and 'content'
        temperature: Temperature setting (will be ignored for models that don't support it)
        seed: Optional seed for deterministic responses
    Returns:
        The model's response content as a string
    """
    import time

    # Only use temperature if it's not 1.0 (default) or if the model supports it
    kwargs = {
        "model": model,
        "messages": messages,
        "seed": seed,
    }
    # Only add temperature if it's not the default value of 1.0
    # or if we're using a model that supports custom temperature
    if temperature != 1.0 and not model.startswith("o4-mini"):
        kwargs["temperature"] = temperature

    max_retries = 3
    for attempt in range(max_retries):
        try:
            resp = client.chat.completions.create(**kwargs)
            return resp.choices[0].message.content
        except Exception as e:
            if attempt == max_retries - 1:
                raise RuntimeError(f"LLM call failed after {max_retries} attempts: {e}")
            print(f"LLM call attempt {attempt + 1} failed: {e}. Retrying in {2 ** attempt} seconds...")
            time.sleep(2 ** attempt)  # Exponential backoff


def persist_result(record: Dict[str, Any], out_jsonl: Union[str, Path]) -> None:
    """
    Generic function to append a single JSON record to a JSONL file.
    Used across the pipeline for persisting queries, groundtruth, and verdicts.
    Args:
        record: Dictionary containing the data to persist
        out_jsonl: Path to the output JSONL file
    """
    out = Path(out_jsonl)
    out.parent.mkdir(parents=True, exist_ok=True)
    with out.open("a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")


def load_database_ddl(
    ddl_file_path: Union[str, Path],
) -> str:
    """
    Load DDL context from .sql file.
    Args:
        - ddl_file_path: the path to the .sql DDL file
    Returns:
        - A string containing the DDL statements
    """
    sql_file = pathlib.Path(ddl_file_path)
    if not sql_file.exists():
        raise FileNotFoundError(f"Database DDL file not found at: {ddl_file_path}")

    if sql_file.suffix.lower() != ".sql":
        raise ValueError(f"Expected .sql file, got: {sql_file}")

    ddl_content = sql_file.read_text(encoding="utf-8").strip()
    if not ddl_content:
        raise ValueError(f"DDL file is empty: {sql_file}")

    return ddl_content


def load_problem_family(problem_family_file: Union[str, Path]) -> Dict[str, Any]:
    """
    Load the problem family configuration from JSON file.
    Args:
        problem_family_file: Path to problem_family.json
    Returns:
        Dict containing the problem family configuration
    """
    path = Path(problem_family_file)
    if not path.exists():
        raise FileNotFoundError(f"Problem family file not found: {path}")

    with path.open("r", encoding="utf-8") as f:
        return json.load(f)


def load_query(
    *,
    query_id: str,
    query_bank_file: Union[str, Path],
) -> str:
    """
    Load the natural-language query given its ID from query bank.
    Args:
        - query_id: The UUID of the query generated by query_generator.py.
        - query_bank_file: The path to the query bank file.
    Returns:
        - The natural-language query.
    """
    qbank = Path(query_bank_file)
    if not qbank.exists():
        raise FileNotFoundError(f"query_bank not found: {qbank}")

    with qbank.open("r", encoding="utf-8") as f:
        for line in f:
            obj = json.loads(line)
            if obj.get("id") == query_id:
                query = obj.get("query")
                if not isinstance(query, str):
                    raise ValueError(
                        f"Record for id '{query_id}' has no valid 'query' string."
                    )
                return query.strip()

    raise KeyError(f"id '{query_id}' not found in {qbank}")


def load_groundtruth_record(
    *,
    query_id: str,
    groundtruth_bank_file: Union[str, Path],
) -> Dict[str, Any]:
    """
    Load a groundtruth record by query_id from the groundtruth bank file.
    Args:
        query_id: The query ID to look for
        groundtruth_bank_file: Path to the groundtruth bank file
    Returns:
        Dict containing the groundtruth record
    """
    bank_path = Path(groundtruth_bank_file)
    if not bank_path.exists():
        raise FileNotFoundError(f"Groundtruth bank not found: {bank_path}")

    with bank_path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                record = json.loads(line)
            except Exception:
                continue
            if record.get("id") == query_id:
                return record

    raise KeyError(f"Query ID '{query_id}' not found in groundtruth bank: {bank_path}")


def load_result_db(
    *,
    query_id: str,
    result_db_path: Union[str, Path],
    row_limit: Optional[int] = None,
    use_full_data: bool = False,
) -> Dict[str, Any]:
    """
    Return the result table and column names.
    Output shape:
        {
          "columns": ["col1", "col2", ...],
          "rows": [[...], [...], ...]   # rows (limited by row_limit if specified)
        }
    Args:
        query_id: ID of the query to load results for
        result_db_path: Path to the verdict directory containing result .sqlite files
        row_limit: Optional limit on number of rows to return (ignored if use_full_data=True)
        use_full_data: If True, load all rows; if False, use row_limit
    """
    db_path = Path(result_db_path) / f"{query_id}.sqlite"
    if not db_path.exists():
        raise FileNotFoundError(f"Result DB not found: {db_path}")

    conn = None
    try:
        conn = sqlite3.connect(str(db_path))
        cur = conn.cursor()

        # Ensure result table exists
        cur.execute(
            "SELECT name FROM sqlite_master WHERE type='table' AND name='result'"
        )
        if not cur.fetchone():
            raise ValueError(f"Table result not found in {db_path}")

        # Column names
        cur.execute('PRAGMA table_info("result")')
        cols = cur.fetchall()  # cid, name, type, notnull, dflt_value, pk
        columns = [str(name) for _, name, *_ in cols]

        # Load rows (with optional limit)
        if use_full_data:
            # Load all rows when full data is requested
            cur.execute('SELECT * FROM "result"')
        elif row_limit is not None:
            # Load limited rows
            cur.execute('SELECT * FROM "result" LIMIT ?', (row_limit,))
        else:
            # Load all rows (default behavior)
            cur.execute('SELECT * FROM "result"')
        rows = [list(r) for r in cur.fetchall()]

        return {"columns": columns, "rows": rows}

    finally:
        if conn is not None:
            try:
                conn.close()
            except Exception:
                pass


def load_sql(query_id: str, groundtruth_bank_file: Union[str, Path]) -> str:
    """
    Load the SQL text for a given query id from a .jsonl groundtruth bank file.
    """
    bank_path = Path(groundtruth_bank_file)
    if not bank_path.exists():
        raise FileNotFoundError(f"Groundtruth bank file not found: {bank_path}")
    with bank_path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
            except Exception:
                continue
            if obj.get("id") == query_id:
                sql = obj.get("sql", "")
                if not sql:
                    raise ValueError(
                        f"No SQL found for query_id '{query_id}' in {bank_path}"
                    )
                return sql.strip()
    raise KeyError(f"Query ID '{query_id}' not found in {bank_path}")


def get_difficulty_range(
    problem_family_file: Union[str, Path], difficulty: str
) -> Dict[str, float]:
    """
    Get the score range for a given difficulty level.
    Args:
        problem_family_file: The path to the problem family file
        difficulty: The difficulty level ("easy", "medium", "hard")
    Returns:
        Dict with "min" and "max" score values
    """
    difficulty_norm = difficulty.strip().lower()
    problem_family = load_problem_family(problem_family_file)
    levels = problem_family.get("difficulty", {}).get("levels", {})

    if difficulty_norm not in levels:
        available = ", ".join(sorted(levels.keys()))
        raise ValueError(f"Unknown difficulty '{difficulty}'. Available: {available}")

    return levels[difficulty_norm]


def calculate_difficulty(
    specification: Dict[str, Any], problem_family_config: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Calculate difficulty based on problem family and selected features.
    Args:
        specification: Dict with 'problem_family', 'selected_features', etc.
        problem_family_config: The loaded problem family configuration
    Returns:
        Dict with 'difficulty', 'target_score_range', 'problem_family', and 'selected_features' keys
    """
    problem_family = specification.get("problem_family", "")
    selected_features = specification.get("selected_features", [])

    if not isinstance(selected_features, list):
        selected_features = []

    # Calculate total difficulty score
    total_score = 0.0

    # Add problem family base score
    problem_family_base_scores = problem_family_config.get("problem_family_base", {})
    if problem_family in problem_family_base_scores:
        base_score = problem_family_base_scores[problem_family]
        total_score += base_score

    # Add selected feature scores
    family_features = problem_family_config.get("family_features", {}).get(problem_family, {})
    for feature_name in selected_features:
        if feature_name in family_features:
            feature_score = family_features[feature_name].get("difficulty_score", 0.0)
            total_score += feature_score

    # Determine difficulty level based on total score
    difficulty_levels = problem_family_config.get("difficulty", {}).get("levels", {})

    difficulty = "easy"  # default
    target_range = {"min": 0.0, "max": 2.4}  # default

    for level_name, level_range in difficulty_levels.items():
        min_score = level_range.get("min", 0.0)
        max_score = level_range.get("max", 99.0)

        if min_score <= total_score <= max_score:
            difficulty = level_name
            target_range = {"min": min_score, "max": max_score}
            break

    return {
        "difficulty": difficulty,
        "target_score_range": target_range,
        "problem_family": problem_family,
        "selected_features": selected_features,
        "total_difficulty_score": total_score,
    }
